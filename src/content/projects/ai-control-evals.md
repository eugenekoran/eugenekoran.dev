---
title: "AI Control Evaluations"
description: "Designed and implemented a comprehensive evaluation framework to validate AI control protocols outlined in the 'AI Control: Improving Safety Despite Intentional Subversion' paper."
pubDate: 2025-06-01
tags: ["AI Safety", "AI Control", "Inspect AI", "Python"]
---

## Overview

A systematic evaluation framework for validating the effectiveness of AI control protocols. This project implements and tests the key defense mechanisms proposed in the foundational AI Control paper, providing empirical evidence of their effectiveness against various attack policies.

## Key Contributions

- Developed a systematic testing methodology to assess safety and usefulness of various control protocols against attack policies
- Successfully implemented and validated key defense protocols from the original research
- Provided empirical evidence of protocol effectiveness in controlled experimental settings

## Links

- [GitHub Repository](https://github.com/eugenekoran/ai-control-evals)

## Technologies

Python, Docker, Inspect AI, OpenAI API
