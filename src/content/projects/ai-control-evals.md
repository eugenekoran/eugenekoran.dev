---
title: "AI Control Evaluations"
description: "Designed and implemented a comprehensive evaluation framework to validate AI control protocols outlined in the 'AI Control: Improving Safety Despite Intentional Subversion' paper."
pubDate: 2025-05-24
tags: ["AI Safety", "AI Control", "Inspect AI", "Python"]
---

## Overview

A systematic evaluation framework for validating the effectiveness of AI control protocols. This project implements and tests the key defense mechanisms proposed in the foundational AI Control paper, providing empirical evidence of their effectiveness against various attack policies.

## Key Contributions

- Developed a systematic testing methodology to assess safety and usefulness of various control protocols against attack policies
- Successfully implemented and validated key protocols from the original research

## Links

- [GitHub Repository](https://github.com/eugenekoran/ai-control-evals)
- [Original Paper](https://arxiv.org/abs/2312.06942) â€” AI Control: Improving Safety Despite Intentional Subversion

## Technologies

Python, Docker, Inspect AI, OpenAI API
